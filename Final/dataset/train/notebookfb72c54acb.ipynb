{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:3]:\n        print(os.path.join(dirname, filename))\n    if len(filenames) > 3:\n        print(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-02T13:29:44.223667Z","iopub.execute_input":"2023-05-02T13:29:44.224742Z","iopub.status.idle":"2023-05-02T13:30:09.601244Z","shell.execute_reply.started":"2023-05-02T13:29:44.224695Z","shell.execute_reply":"2023-05-02T13:30:09.599843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport cv2\nimport numpy as np\nimport random\nimport os\n\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:09.60334Z","iopub.execute_input":"2023-05-02T13:30:09.603779Z","iopub.status.idle":"2023-05-02T13:30:12.245436Z","shell.execute_reply.started":"2023-05-02T13:30:09.603739Z","shell.execute_reply":"2023-05-02T13:30:12.244056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/captcha-hacker-2023-spring/dataset/train\"\nTEST_PATH = \"/kaggle/input/captcha-hacker-2023-spring/dataset/test\"\ndevice = \"cpu\"\n# try device = \"cuda\" \n# and change your settings/accelerator to GPU if you want it to run faster if your using kaggle's enviroment","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.247135Z","iopub.execute_input":"2023-05-02T13:30:12.248359Z","iopub.status.idle":"2023-05-02T13:30:12.255007Z","shell.execute_reply.started":"2023-05-02T13:30:12.248305Z","shell.execute_reply":"2023-05-02T13:30:12.253721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nalphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.25695Z","iopub.execute_input":"2023-05-02T13:30:12.257306Z","iopub.status.idle":"2023-05-02T13:30:12.267431Z","shell.execute_reply.started":"2023-05-02T13:30:12.25727Z","shell.execute_reply":"2023-05-02T13:30:12.266116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Task1Dataset(Dataset):\n    def __init__(self, data, root, return_filename=False):\n        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n        self.return_filename = return_filename\n        self.root = root\n    \n    def __getitem__(self, index):\n        filename, label = self.data[index]\n        img = cv2.imread(f\"{self.root}/{filename}\")\n        img = cv2.resize(img, (32, 32))\n        img = np.mean(img, axis=2)\n        if self.return_filename:\n            return torch.FloatTensor((img - 128) / 128), filename\n        else:\n            return torch.FloatTensor((img - 128) / 128), alphabets2index[label]\n\n    def __len__(self):\n        return len(self.data)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.271936Z","iopub.execute_input":"2023-05-02T13:30:12.272509Z","iopub.status.idle":"2023-05-02T13:30:12.283675Z","shell.execute_reply.started":"2023-05-02T13:30:12.272469Z","shell.execute_reply":"2023-05-02T13:30:12.282394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(1024, 512),\n            nn.LeakyReLU(),\n            nn.Linear(512, len(alphabets))\n        )\n        \n        \n    def forward(self, x):\n        batch_size, h, w = x.shape\n        x = x.view(batch_size, h*w)\n        return self.layers(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.284689Z","iopub.execute_input":"2023-05-02T13:30:12.285574Z","iopub.status.idle":"2023-05-02T13:30:12.296951Z","shell.execute_reply.started":"2023-05-02T13:30:12.285523Z","shell.execute_reply":"2023-05-02T13:30:12.295556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = []\nval_data = []\n\nwith open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        if random.random() < 0.8:\n            train_data.append(row)\n        else:\n            val_data.append(row)\n\ntrain_ds = Task1Dataset(train_data, root=TRAIN_PATH)\ntrain_dl = DataLoader(train_ds, batch_size=100, num_workers=4, drop_last=True, shuffle=True)\n\nval_ds = Task1Dataset(val_data, root=TRAIN_PATH)\nval_dl = DataLoader(val_ds, batch_size=100, num_workers=4, drop_last=False, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.298708Z","iopub.execute_input":"2023-05-02T13:30:12.299406Z","iopub.status.idle":"2023-05-02T13:30:12.328307Z","shell.execute_reply.started":"2023-05-02T13:30:12.299367Z","shell.execute_reply":"2023-05-02T13:30:12.327111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = nn.CrossEntropyLoss()\n\n\nfor epoch in range(50):\n    print(f\"Epoch [{epoch}]\")\n    model.train()\n    for image, label in train_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = model(image)\n        loss = loss_fn(pred, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n    sample_count = 0\n    correct_count = 0\n    model.eval()\n    for image, label in val_dl:\n        image = image.to(device)\n        label = label.to(device)\n        \n        pred = model(image)\n        loss = loss_fn(pred, label)\n        \n        pred = torch.argmax(pred, dim=1)\n        \n        sample_count += len(image)\n        correct_count += (label == pred).sum()\n        \n    print(\"accuracy (validation):\", correct_count / sample_count)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:30:12.329982Z","iopub.execute_input":"2023-05-02T13:30:12.330334Z","iopub.status.idle":"2023-05-02T13:31:11.65425Z","shell.execute_reply.started":"2023-05-02T13:30:12.3303Z","shell.execute_reply":"2023-05-02T13:31:11.652784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = []\nwith open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n    for row in csv.reader(csvfile, delimiter=','):\n        test_data.append(row)\n\ntest_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\ntest_dl = DataLoader(test_ds, batch_size=500, num_workers=4, drop_last=False, shuffle=False)\n\n\nif os.path.exists('submission.csv'):\n    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\nelse:\n    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n    csv_writer.writerow([\"filename\", \"label\"])\n\n\nmodel.eval()\nfor image, filenames in test_dl:\n    image = image.to(device)\n    \n    pred = model(image)\n    pred = torch.argmax(pred, dim=1)\n    \n    for i in range(len(filenames)):\n        csv_writer.writerow([filenames[i], alphabets[pred[i].item()]])\n\nfor filename, _ in test_data:\n    if filename.startswith(\"task2\") or filename.startswith(\"task3\"):\n        csv_writer.writerow([filename, 0])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T13:31:11.656181Z","iopub.execute_input":"2023-05-02T13:31:11.656569Z","iopub.status.idle":"2023-05-02T13:31:24.418188Z","shell.execute_reply.started":"2023-05-02T13:31:11.656526Z","shell.execute_reply":"2023-05-02T13:31:24.41663Z"},"trusted":true},"execution_count":null,"outputs":[]}]}